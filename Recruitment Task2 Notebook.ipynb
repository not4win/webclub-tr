{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ashwin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading ham and spam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_filenames=os.listdir(os.path.join(\"spam\"))\n",
    "ham_filenames=os.listdir(os.path.join(\"easy_ham\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "def load_email(directory,filename):\n",
    "    with open(os.path.join(directory, filename), \"rb\") as f:\n",
    "     return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(\"easy_ham\", filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(\"spam\", filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(ham_emails+spam_emails)\n",
    "Y=np.array([0]*len(ham_emails)+[1]*len(spam_emails))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all emails to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def html_text(html):\n",
    "    soup = BeautifulSoup(html,\"html\")\n",
    "    return soup.get_text()\n",
    "    \n",
    "def email_to_text(email):\n",
    "    # Enter code  #\n",
    "    \n",
    "    return str(email.get_payload())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'get', 'would', 'list', 'new', 'like', 'people', 'use', 'email', 'mailing', 'also', 'make', 'free', 'even', 'could', 'time', 'think', 'first', 'using', 'many', 'want', 'see', 'know', 'may', 'way', 'much', 'message', 'need', 'work', 'send', 'please', 'good', 'find', 'take', 'still', 'sep', 'money', 'world', 'united', 'business', 'linux', 'two', 'every', 'government', 'object', 'mail', 'states', 'said', 'really', 'something', 'must', 'since', 'internet', 'years', 'best', 'help', 'web', 'software', 'made', 'last', 'got', 'used', 'right', 'line', 'next', 'spam', 'without', 'old', 'information', 'might', 'found', 'file', 'change', 'name', 'another', 'address', 'going', 'back', 'better', 'data', 'well', 'different', 'system', 'messages', 'sure', 'set', 'say', 'never', 'within', 'give', 'xml', 'technology', 'report', 'look', 'run', 'sponsored', 'security', 'september', 'actually', 'order', 'number', 'put', 'come', 'million', 'great', 'keep', 'home', 'company', 'network', 'long', 'problem', 'public', 'end', 'probably', 'try', 'american', 'computer', 'real', 'support', 'president', 'start', 'things', 'seems', 'anyone', 'someone', 'companies', 'files', 'receive', 'build', 'received', 'part', 'less', 'read', 'groups', 'supplied', 'global', 'state', 'click', 'per', 'aug', 'access', 'around', 'package', 'looking', 'trying', 'done', 'little', 'working', 'thing', 'server', 'running', 'program', 'ever', 'lot', 'service', 'least', 'user', 'day', 'matthias', 'following', 'check', 'based', 'subject', 'national', 'always', 'bush', 'maybe', 'anything', 'current', 'says', 'trade', 'key', 'red', 'unseen', 'call', 'getting', 'nothing', 'three', 'big', 'life', 'times', 'point', 'able', 'code', 'news', 'version', 'rpm', 'provide', 'high', 'making', 'total', 'called', 'special', 'add', 'sent', 'perl', 'phone', 'site', 'offer', 'open', 'already', 'international', 'place', 'including', 'thought', 'development', 'link', 'exmh', 'economic', 'communications', 'war', 'political', 'hat', 'test', 'market', 'future', 'upon', 'problems', 'easy', 'remove', 'msgs', 'tell', 'year', 'case', 'else', 'become', 'power', 'enough', 'given', 'services', 'seem', 'several', 'rights', 'seen', 'wish', 'important', 'marketing', 'tried', 'personal', 'human', 'datapower', 'went', 'html', 'text', 'save', 'believe', 'receiving', 'irish', 'contact', 'let', 'allow', 'thanks', 'hard', 'capital', 'second', 'rather', 'large', 'women', 'stuff', 'error', 'live', 'local', 'instead', 'person', 'install', 'quite', 'small', 'move', 'return', 'came', 'release', 'far', 'available', 'days', 'often', 'log', 'whether', 'unsubscribe', 'simply', 'addresses', 'guide', 'grants', 'makes', 'federal', 'top', 'legal', 'august', 'group', 'pay', 'java', 'cell', 'include', 'kind', 'whole', 'original', 'digital', 'welcome', 'create', 'bit', 'tired', 'show', 'military', 'stop', 'idea', 'act', 'currently', 'means', 'via', 'systems', 'either', 'months', 'single', 'law', 'buy', 'simple', 'almost', 'hit', 'country', 'source', 'major', 'financial', 'geek', 'foreign', 'works', 'lost', 'spamassassin', 'pretty', 'online', 'although', 'packages', 'told', 'product', 'today', 'everything', 'men', 'sending', 'search', 'removed', 'control', 'yet', 'possible', 'load', 'account', 'known', 'wrote', 'form', 'past', 'complete', 'looks', 'users', 'gets', 'recent', 'thousands', 'full', 'investment', 'feel', 'due', 'osdn', 'remember', 'john', 'windows', 'story', 'family', 'private', 'process', 'bill', 'venture', 'training', 'research', 'office', 'early', 'directory', 'join', 'growing', 'bad', 'posted', 'bank', 'building', 'continue', 'opportunity', 'processing', 'understand', 'half', 'force', 'root', 'page', 'type', 'though', 'perhaps', 'word', 'write', 'drive', 'cash', 'cannot', 'university', 'sponsor', 'similar', 'october', 'kernel', 'application', 'mean', 'america', 'week', 'reason', 'dollars', 'sites', 'saou', 'friends', 'increase', 'away', 'price', 'man', 'others', 'learn', 'device', 'response', 'worked', 'countries', 'fact', 'general', 'false', 'kingdom', 'living', 'left', 'respect', 'needs', 'happy', 'across', 'value', 'needed', 'hours', 'freedom', 'results', 'air', 'course', 'copyright', 'experience', 'nice', 'step', 'protect', 'area', 'claim', 'behalf', 'contains', 'box', 'exactly', 'installed', 'size', 'pgp', 'rate', 'emails', 'orders', 'everyone', 'comes', 'lawrence', 'developing', 'potential', 'wanted', 'ability', 'sell', 'center', 'question', 'according', 'reading', 'started', 'month', 'fall', 'wants', 'worth', 'job', 'interest', 'programs', 'finding', 'cost', 'alsa', 'enenkio', 'income', 'entire', 'numbers', 'oct', 'usa', 'folder', 'hope', 'easily', 'method', 'amount', 'database', 'true', 'interested', 'mind', 'lots', 'plan', 'common', 'copy', 'daily', 'especially', 'language', 'starting', 'marshall', 'various']\n"
     ]
    }
   ],
   "source": [
    "def clean_words(wordlist):\n",
    "    newlist=[]\n",
    "    stemmer=PorterStemmer()\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    for word in wordlist:\n",
    "        if (word.isalpha() and word not in stop_words and len(word)>2):\n",
    "            #can also implement stemming by stemmer.stem(word)\n",
    "            newlist.append(word)\n",
    "            \n",
    "   \n",
    "    return newlist\n",
    "\n",
    "count=0\n",
    "word_list=[]\n",
    "for i in X_train:\n",
    "    mail=email_to_text(i)\n",
    "    if mail is not None:\n",
    "        words=None\n",
    "        words=mail.lower().split()\n",
    "        final_word=clean_words(words)\n",
    "        for w in final_word:\n",
    "            word_list.append(w)\n",
    "\n",
    "most_common_words= [word for word, word_count in Counter(word_list).most_common(500)]\n",
    "most_common = [item for item in Counter(word_list).most_common(500)]\n",
    "print(most_common_words)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1500x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33011 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform=[]\n",
    "for email in X_train[:1500]:    \n",
    "    mail=email_to_text(email)\n",
    "    X_word=[]\n",
    "    if mail is not None:\n",
    "        words=None\n",
    "        words=mail.lower().split()\n",
    "        for j in most_common_words:\n",
    "            num=words.count(j)\n",
    "            X_word.append(num)\n",
    "    \n",
    "    X_transform.append(X_word) \n",
    "\n",
    "from scipy import sparse\n",
    "sparse.csr_matrix(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333225476687852"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bonus Task #\n",
    "# Fine tune the hyperparameters #\n",
    "lg=RandomForestClassifier()\n",
    "lg.fit(X_transform,Y_train[:1500])\n",
    "score = cross_val_score(lg, X_transform, Y_train[:1500], cv=10, verbose=0)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
